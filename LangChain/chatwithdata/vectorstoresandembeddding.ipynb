{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstores and Embeddings\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just discussed Document Loading and Splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"https://cs229.stanford.edu/notes2021fall/cs229-notes1.pdf\"),\n",
    "    PyPDFLoader(\"https://cs229.stanford.edu/notes2021fall/cs229-notes1.pdf\"),\n",
    "    PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf\"),\n",
    "    PyPDFLoader(\"https://see.stanford.edu/materials/aimlcs229/cs229-notes3.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Let's take our splits and embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963190818034527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7711177200797418"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596334120325523"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mined (according top(y))asbefore. Then, thesender oftheemail writes the\\nemail by\\x0crstgenerating x1fromsome multinomial distribution overwords\\n(p(x1jy)).Next, thesecond wordx2ischosen independen tlyofx1butfrom\\nthesame multinomial distribution, andsimilarly forx3,x4,andsoon,until\\nallnwordsoftheemail havebeengenerated. Thus,theoverallprobabilit yof\\namessage isgivenbyp(y)Qn\\ni=1p(xijy).Notethatthisformulalookslikethe\\nonewehadearlier fortheprobabilit yofamessage under themulti-variate\\nBernoulli eventmodel,butthattheterms intheformulanowmean verydif-\\nferentthings. Inparticular xijyisnowamultinomial, rather thanaBernoulli\\ndistribution.\\nTheparameters forournewmodelare\\x1ey=p(y)asbefore, \\x1eijy=1=\\np(xj=ijy=1)(foranyj)and\\x1eijy=0=p(xj=ijy=0).Notethatwehave\\nassumed thatp(xjjy)isthesameforallvaluesofj(i.e.,thatthedistribution\\naccording towhichawordisgenerated doesnotdependonitsposition j\\nwithin theemail).\\nIfwearegivenatraining setf(x(i);y(i));i=1;:::;mgwhere x(i)=\\n(x(i)\\n1;x(i)\\n2;:::;x(i)\\nni)(here, niisthenumberofwordsinthei-training example),'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this so we can use it later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure modes\n",
    "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
    "\n",
    "But there are some failure modes that can creep up.\n",
    "\n",
    "Here are some edge cases that can arise - we'll fix them in the next class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're getting duplicate chunks (because of the duplicate MachineLearning-Lecture01.pdf in the index).\n",
    "\n",
    "Semantic search fetches all similar documents, but does not enforce diversity.\n",
    "\n",
    "docs[0] and docs[1] are indentical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='ni\\x0ccan tinsigh tintothestructure oftheproblem, andwerealsoabletowrite\\ntheentirealgorithm interms ofonlyinner products betweeninput feature\\nvectors. Inthenextsection, wewillexploit thispropertytoapply theker-\\nnelstoourclassi\\x0ccation problem. Theresulting algorithm, supportvector\\nmachines ,willbeabletoe\\x0ecien tlylearn inveryhighdimensional spaces.\\n7Kernels\\nBackinourdiscussion oflinear regression, wehadaproblem inwhichthe\\ninput xwastheliving areaofahouse, andweconsidered performing regres-', metadata={'page': 12, 'source': 'C:\\\\Users\\\\alexm\\\\AppData\\\\Local\\\\Temp\\\\tmppfmxqozb\\\\tmp.pdf'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a new failure mode.\n",
    "\n",
    "The question below asks a question about the third lecture, but includes results from other lectures as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 1, 'source': 'C:\\\\Users\\\\alexm\\\\AppData\\\\Local\\\\Temp\\\\tmps28qlbe1\\\\tmp.pdf'}\n",
      "{'page': 1, 'source': 'C:\\\\Users\\\\alexm\\\\AppData\\\\Local\\\\Temp\\\\tmpepkj5t9_\\\\tmp.pdf'}\n",
      "{'page': 0, 'source': 'C:\\\\Users\\\\alexm\\\\AppData\\\\Local\\\\Temp\\\\tmpgsbgz6ge\\\\tmp.pdf'}\n",
      "{'page': 12, 'source': 'C:\\\\Users\\\\alexm\\\\AppData\\\\Local\\\\Temp\\\\tmppfmxqozb\\\\tmp.pdf'}\n",
      "{'page': 2, 'source': 'C:\\\\Users\\\\alexm\\\\AppData\\\\Local\\\\Temp\\\\tmps28qlbe1\\\\tmp.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Part I\n",
      "Linear Regression\n",
      "To make our housing example more interesting, let’s consider a slightly richer\n",
      "dataset in which we also know the number of bedrooms in each house:\n",
      "Living area (feet2)#bedrooms Price (1000$s)\n",
      "2104 3 400\n",
      "1600 3 330\n",
      "2400 3 369\n",
      "1416 2 232\n",
      "3000 4 540\n",
      ".........\n",
      "Here, thex’s are two-dimensional vectors in R2. For instance, x(i)\n",
      "1is the\n",
      "living area of the i-th house in the training set, and x(i)\n",
      "2is its number of\n",
      "bedrooms. (In general, when designing a learning problem, it will be up to\n",
      "you to decide what features to choose, so if you are out in Portland gathering\n",
      "housing data, you might also decide to include other features such as whether\n",
      "each house has a ﬁreplace, the number of bathrooms, and so on. We’ll say\n",
      "more about feature selection later, but for now let’s take the features as\n",
      "given.)\n",
      "To perform supervised learning, we must decide how we’re going to rep-\n",
      "resent functions/hypotheses hin a computer. As an initial choice, let’s say\n",
      "we decide to approximate yas a linear function of x:\n",
      "hθ(x) =θ0+θ1x1+θ2x2\n",
      "Here, theθi’s are the parameters (also called weights ) parameterizing the\n",
      "space of linear functions mapping from XtoY. When there is no risk of\n",
      "confusion, we will drop the θsubscript in hθ(x), and write it more simply as\n",
      "h(x). To simplify our notation, we also introduce the convention of letting\n",
      "x0= 1 (this is the intercept term ), so that\n",
      "h(x) =d∑\n",
      "i=0θixi=θTx,\n",
      "where on the right-hand side above we are viewing θandxboth as vectors,\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaches discussed in the next lecture can be used to address both!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
